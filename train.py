import tensorflow as tf
import numpy as np
from Unet import UNet
from discriminator import Discriminator
import os
from PIL import Image

class Train():
    def __init__(self):

        #realA
        realA = tf.placeholder(tf.float32, shape=[None,398,398,3])
        
        #realB
        reshaped_realB = tf.placeholder(tf.float32, shape=[None,398,398,3])
        realB = tf.placeholder(tf.float32, shape=[None,572,572,3])

        #batch_size
        batch_size = realA.get_shape().as_list()[0]
        
        #Generated by UNet used realB
        #fakeA
        fakeB = UNet(realB).dec_conv_last

        #concat
        #positive
        #realAB
        realAB = tf.concat([realA,reshaped_realB], 3)        
        #negative
        #fakeAB
        fakeAB = tf.concat([realA,fakeB], 3)
        
        #discriminator
        dis_real = Discriminator(realAB, batch_size)
        real_logits = dis_real.last_h
        real_out = dis_real.out

        dis_fake = Discriminator(fakeAB, batch_size)
        fake_logits = dis_fake.last_h
        fake_out = dis_fake.out

        self.d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_logits, labels=tf.ones_like(real_out)))
        self.d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.ones_like(fake_out)))
        self.UNet_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.ones_like(fake_out)))

        self.d_loss = self.d_loss_fake + self.d_loss_real

        self.opt_d = tf.train.AdamOptimizer(0.0003).minimize(self.d_loss)
        self.opt_g = tf.train.AdamOptimizer(0.0003).minimize(self.UNet_loss)

def sample(size, channel, path):
    '''
        input : dir string 
              : size int
              : channel int
              dir is used for path to load image 
              size is height and width
              As example ,when image is RGBcolor ,channel is 3
        output:out put dims are [batchsize, height, width, channel]
    '''
    imgs = np.array([])
    for n in os.listdir(path):
        img = np.array(Image.open(path+n))
        imgs = np.append(imgs,img)
    print(imgs.shape)

sample(64, 3, './data/rgb398/')

'''
train = Train()
with tf.Session() as sess:
    tf.global_variables_initializer.run()
    saver = tf.train.Saver(tf.global_variables())
'''
